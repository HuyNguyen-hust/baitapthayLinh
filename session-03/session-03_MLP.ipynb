{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"session-03_MLP.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1pjM_EblPMfVh5AIlESzjYawLblszpgkd","authorship_tag":"ABX9TyM4zar3w2GDAWs+iqwAR1Iu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"htVJD9H0hCDJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619531526138,"user_tz":-420,"elapsed":3856,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}},"outputId":"a71d8dba-cfa0-4577-f71a-e50f8f6401a5"},"source":["import numpy as np\n","import random\n","import os\n","\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Dni8NfqcZOKG","executionInfo":{"status":"ok","timestamp":1619531526138,"user_tz":-420,"elapsed":3852,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["tf.compat.v1.disable_eager_execution()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTJvWN-Rh7s6","executionInfo":{"status":"ok","timestamp":1619531526139,"user_tz":-420,"elapsed":3851,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["class MLP:\n","  def __init__(self, vocab_size, hidden_size, NUM_CLASSES):\n","    self._vocab_size = vocab_size\n","    self._hidden_size = hidden_size\n","    self.NUM_CLASSES = NUM_CLASSES\n","  def build_graph(self):\n","    self._X = tf.placeholder(tf.float32, shape = [None, self._vocab_size])\n","    self._real_y = tf.placeholder(tf.int32, shape = [None, ])\n","\n","    with tf.variable_scope('w1', reuse = tf.AUTO_REUSE):\n","      weights_1 = tf.get_variable(\n","          name = 'weight_input_hidden',\n","          shape = (self._vocab_size, self._hidden_size),\n","          initializer = tf.random_normal_initializer(seed = 2021)\n","      )\n","\n","    with tf.variable_scope('b1', reuse = tf.AUTO_REUSE):\n","      biases_1 = tf.get_variable(\n","          name = 'biases_input_hidden',\n","          shape = (self._hidden_size),\n","          initializer = tf.random_normal_initializer(seed = 2021)\n","      )\n","\n","    with tf.variable_scope('w2', reuse = tf.AUTO_REUSE):\n","      weights_2 = tf.get_variable(\n","          name = 'weight_input_output',\n","          shape = (self._hidden_size, self.NUM_CLASSES),\n","          initializer = tf.random_normal_initializer(seed = 2021)\n","      )\n","    \n","    with tf.variable_scope('b2', reuse = tf.AUTO_REUSE):\n","      biases_2 = tf.get_variable(\n","          name = 'biases_input_hidden',\n","          shape = (self.NUM_CLASSES),\n","          initializer = tf.random_normal_initializer(seed = 2021)\n","      )\n","\n","    hidden = tf.matmul(self._X, weights_1) + biases_1\n","    hidden = tf.sigmoid(hidden)\n","    logits = tf.matmul(hidden, weights_2) + biases_2\n","    \n","    labels_one_hot = tf.one_hot(indices = self._real_y, depth = self.NUM_CLASSES, dtype = tf.float32)\n","    loss = tf.nn.softmax_cross_entropy_with_logits(labels = labels_one_hot, logits = logits)\n","    loss = tf.reduce_mean(loss)\n","\n","    probs = tf.nn.softmax(logits)\n","    predicted_labels = tf.argmax(probs, axis = 1)\n","    predicted_labels = tf.squeeze(predicted_labels)\n","\n","    return predicted_labels, loss\n","\n","  def trainer(self, loss, learning_rate):\n","    with tf.variable_scope('op', reuse = tf.AUTO_REUSE):\n","      train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n","    return train_op"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBRi3gr8X3k4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619531531390,"user_tz":-420,"elapsed":9095,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}},"outputId":"85eb21b2-31b7-46ed-afa4-c0ca567e8724"},"source":["path = '/datasets/20news-bydate'\n","with open(path + '/words_idfs.txt') as f:\n","  vocab_size = len(f.read().splitlines())\n","\n","mlp = MLP(\n","    vocab_size = vocab_size,\n","    hidden_size = 50,\n","    NUM_CLASSES = 20\n",")\n","\n","predicted_labels, loss = mlp.build_graph()\n","\n","train_op = mlp.trainer(loss = loss, learning_rate = 0.1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xg2RzJ2hzbm4","executionInfo":{"status":"ok","timestamp":1619531531391,"user_tz":-420,"elapsed":9094,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["class DataReader:\n","  def __init__(self, path, batch_size, vocab_size):\n","    self._batch_size = batch_size\n","    with open(path, encoding = 'ISO-8859-1') as f:\n","      d_lines = f.read().splitlines()\n","    self._data = []\n","    self._labels = []\n","    \n","    for data_id, line in enumerate(d_lines):\n","      vector = [0.0 for _ in range(vocab_size)]\n","      features = line.split('<fff>')\n","      label, doc_id = int(features[0]), int(features[1])\n","      tokens = features[2].split()\n","      for token in tokens:\n","        index, value = int(token.split(':')[0]), float(token.split(':')[1])\n","        vector[index] = value\n","      self._data.append(vector)\n","      self._labels.append(label)\n","    \n","    self._data = np.array(self._data)\n","    self._labels = np.array(self._labels)\n","\n","    self._num_epoch = 0\n","    self._batch_id = 0\n","  \n","  def next_batch(self):\n","    start = self._batch_id * self._batch_size\n","    end = start + self._batch_size\n","    self._batch_id += 1\n","\n","    if end + self._batch_size > len(self._data):\n","      end = len(self._data)\n","      self._num_epoch += 1\n","      self._batch_id = 0\n","      indices = range(len(self._data))\n","      random.seed(2021)\n","      random.shuffle(list(indices))\n","      tmp_data = []\n","      tmp_labels = []\n","      for idx in indices:\n","        tmp_data.append(self._data[idx])\n","        tmp_labels.append(self._labels[idx])\n","      self._data, self._labels = tmp_data, tmp_labels\n","    \n","    return self._data[start:end], self._labels[start:end]\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"HuPeF8u6zWsN","executionInfo":{"status":"ok","timestamp":1619531531391,"user_tz":-420,"elapsed":9091,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["def load_dataset():\n","  train_data_reader = DataReader(\n","      path = path + '/20news_train_tfidf.txt',\n","      batch_size = 50,\n","      vocab_size = vocab_size\n","  )\n","  test_data_reader = DataReader(\n","      path = path + '/20news_test_tfidf.txt',\n","      batch_size = 50,\n","      vocab_size = vocab_size\n","  )\n","  \n","  return train_data_reader, test_data_reader\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZyZbuiifIdQ","executionInfo":{"status":"ok","timestamp":1619531532606,"user_tz":-420,"elapsed":10305,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["def save_parameters(name, value, epoch):\n","  filename = name.replace(':', '-colon-') + '-epoch-{}.txt'.format(epoch)\n","  if len(value.shape) == 1:\n","    string_form = ','.join([str(number) for number in value])\n","  else:\n","    string_form = '\\n'.join([','.join([str(number) for number in value[row]]) for row in range(value.shape[0])])\n","  if not os.path.exists(path + '/saved_paras/' + filename.split('/')[0]):\n","    os.mkdir(path + '/saved_paras/' + filename.split('/')[0])\n","  with open(path + '/saved_paras/' + filename, 'w') as f:\n","    f.write(string_form)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"plDN2PdNYba7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619531710464,"user_tz":-420,"elapsed":188158,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}},"outputId":"a09eac0b-539f-4d30-b17f-334cf9cb2511"},"source":["with tf.Session() as sess:\n","  train_data_reader, test_data_reader = load_dataset()\n","  step, MAX_STEP = 0, 30_000\n","  \n","  sess.run(tf.global_variables_initializer())\n","  while step < MAX_STEP:\n","    train_data, train_labels = train_data_reader.next_batch()\n","    plabels_eval, loss_eval, _ = sess.run(\n","        [predicted_labels, loss, train_op],\n","        feed_dict = {\n","            mlp._X: train_data,\n","            mlp._real_y: train_labels\n","        }\n","    )\n","    step += 1\n","    if step % 100 == 0: print('step: {}, loss: {}'.format(step, loss_eval))\n","  \n","  trainable_variables = tf.trainable_variables()\n","  for variable in trainable_variables:\n","    if not os.path.exists(path + '/saved_paras/'):\n","      os.mkdir(path + '/saved_paras/')\n","    save_parameters(\n","        name = variable.name,\n","        value = variable.eval(),\n","        epoch = train_data_reader._num_epoch\n","    )\n","  \n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["step: 100, loss: 3.380756139755249\n","step: 200, loss: 4.678699016571045\n","step: 300, loss: 3.776603937149048\n","step: 400, loss: 0.6784253120422363\n","step: 500, loss: 2.983941078186035\n","step: 600, loss: 0.7472978830337524\n","step: 700, loss: 3.0822641849517822\n","step: 800, loss: 0.0062517630867660046\n","step: 900, loss: 5.262300968170166\n","step: 1000, loss: 0.16384920477867126\n","step: 1100, loss: 0.023481659591197968\n","step: 1200, loss: 0.8647221922874451\n","step: 1300, loss: 0.00037774283555336297\n","step: 1400, loss: 0.2628019452095032\n","step: 1500, loss: 0.011880683712661266\n","step: 1600, loss: 0.15504354238510132\n","step: 1700, loss: 0.002276916755363345\n","step: 1800, loss: 0.00021758633374702185\n","step: 1900, loss: 4.3450108933029696e-05\n","step: 2000, loss: 3.78542099497281e-05\n","step: 2100, loss: 0.00030328790307976305\n","step: 2200, loss: 0.0004473777371458709\n","step: 2300, loss: 0.002018778584897518\n","step: 2400, loss: 0.005366782657802105\n","step: 2500, loss: 0.0011066037695854902\n","step: 2600, loss: 7.411694969050586e-05\n","step: 2700, loss: 7.439596811309457e-05\n","step: 2800, loss: 3.325514626340009e-05\n","step: 2900, loss: 0.00015254919708240777\n","step: 3000, loss: 0.020828690379858017\n","step: 3100, loss: 2.2840684323455207e-05\n","step: 3200, loss: 0.0032407911494374275\n","step: 3300, loss: 0.0011869464069604874\n","step: 3400, loss: 0.014002867043018341\n","step: 3500, loss: 4.422884376253933e-05\n","step: 3600, loss: 2.8547596230055206e-05\n","step: 3700, loss: 6.919162115082145e-05\n","step: 3800, loss: 0.00045502695138566196\n","step: 3900, loss: 0.0001243371661985293\n","step: 4000, loss: 8.10787605587393e-05\n","step: 4100, loss: 0.00020403947564773262\n","step: 4200, loss: 2.1069745343993418e-05\n","step: 4300, loss: 6.954332638997585e-05\n","step: 4400, loss: 0.0004509905120357871\n","step: 4500, loss: 3.293877307442017e-05\n","step: 4600, loss: 0.06989945471286774\n","step: 4700, loss: 5.8979792811442167e-05\n","step: 4800, loss: 7.330779772019014e-05\n","step: 4900, loss: 0.04408895969390869\n","step: 5000, loss: 0.00010003450006479397\n","step: 5100, loss: 2.3603042791364715e-06\n","step: 5200, loss: 3.106185613432899e-05\n","step: 5300, loss: 3.65245396096725e-05\n","step: 5400, loss: 0.0002672432456165552\n","step: 5500, loss: 0.02916184440255165\n","step: 5600, loss: 4.854223152506165e-05\n","step: 5700, loss: 1.757454992912244e-05\n","step: 5800, loss: 3.151623604935594e-05\n","step: 5900, loss: 0.0002910720359068364\n","step: 6000, loss: 1.1735991392924916e-05\n","step: 6100, loss: 9.629115993448067e-06\n","step: 6200, loss: 6.651765943388455e-06\n","step: 6300, loss: 1.0943330153168063e-06\n","step: 6400, loss: 0.0006624815869145095\n","step: 6500, loss: 2.7036162464355584e-06\n","step: 6600, loss: 5.5013984820107e-05\n","step: 6700, loss: 6.942180334590375e-05\n","step: 6800, loss: 0.00010764006583485752\n","step: 6900, loss: 3.375970663910266e-06\n","step: 7000, loss: 1.4826676306256559e-05\n","step: 7100, loss: 3.4636475902516395e-05\n","step: 7200, loss: 7.108045247150585e-05\n","step: 7300, loss: 6.515629138448276e-06\n","step: 7400, loss: 1.0683066648198292e-05\n","step: 7500, loss: 5.07438562635798e-05\n","step: 7600, loss: 0.08236230164766312\n","step: 7700, loss: 4.2932901124004275e-05\n","step: 7800, loss: 3.997988642368e-06\n","step: 7900, loss: 3.836093128484208e-06\n","step: 8000, loss: 6.794889486627653e-07\n","step: 8100, loss: 2.934746362370788e-06\n","step: 8200, loss: 1.1256886864430271e-05\n","step: 8300, loss: 5.912749543313112e-07\n","step: 8400, loss: 0.0013182369293645024\n","step: 8500, loss: 7.963088819451514e-07\n","step: 8600, loss: 0.00023837588378228247\n","step: 8700, loss: 3.2733969419496134e-06\n","step: 8800, loss: 4.543428440229036e-05\n","step: 8900, loss: 3.195268436684273e-05\n","step: 9000, loss: 7.428977369272616e-06\n","step: 9100, loss: 1.9216054170101415e-06\n","step: 9200, loss: 1.2639547094295267e-05\n","step: 9300, loss: 0.0004489811835810542\n","step: 9400, loss: 2.1457641707911534e-07\n","step: 9500, loss: 6.847108579677297e-06\n","step: 9600, loss: 8.916805427361396e-07\n","step: 9700, loss: 8.225402439165919e-07\n","step: 9800, loss: 1.2779174767274526e-06\n","step: 9900, loss: 1.0360518899688032e-05\n","step: 10000, loss: 2.594891884655226e-05\n","step: 10100, loss: 1.122943899645179e-06\n","step: 10200, loss: 2.4084294636850245e-05\n","step: 10300, loss: 3.0040578735679446e-07\n","step: 10400, loss: 1.425653954356676e-05\n","step: 10500, loss: 1.1658426046778914e-06\n","step: 10600, loss: 2.6749878543341765e-06\n","step: 10700, loss: 0.0006021721055731177\n","step: 10800, loss: 1.235916018486023\n","step: 10900, loss: 1.4028902053833008\n","step: 11000, loss: 0.23041991889476776\n","step: 11100, loss: 2.770146369934082\n","step: 11200, loss: 0.018080512061715126\n","step: 11300, loss: 1.1494377851486206\n","step: 11400, loss: 0.014142110012471676\n","step: 11500, loss: 2.1457660537294032e-08\n","step: 11600, loss: 4.191117568552727e-06\n","step: 11700, loss: 0.0\n","step: 11800, loss: 1.003252236841945e-05\n","step: 11900, loss: 3.4979009797098115e-05\n","step: 12000, loss: 0.10694348067045212\n","step: 12100, loss: 0.05775727704167366\n","step: 12200, loss: 0.00010813763219630346\n","step: 12300, loss: 1.430510998545742e-08\n","step: 12400, loss: 0.0\n","step: 12500, loss: 2.179103603339172e-06\n","step: 12600, loss: 0.0\n","step: 12700, loss: 0.032696258276700974\n","step: 12800, loss: 1.3113003660691902e-07\n","step: 12900, loss: 0.04566340148448944\n","step: 13000, loss: 3.955032298108563e-06\n","step: 13100, loss: 7.15255676908555e-09\n","step: 13200, loss: 1.883500573285346e-07\n","step: 13300, loss: 0.0\n","step: 13400, loss: 1.1086160611739615e-06\n","step: 13500, loss: 5.006732521906088e-07\n","step: 13600, loss: 8.892926643966348e-07\n","step: 13700, loss: 2.5973216907004826e-05\n","step: 13800, loss: 5.125934308125579e-07\n","step: 13900, loss: 1.9073478796372e-08\n","step: 14000, loss: 5.287437943479745e-06\n","step: 14100, loss: 1.430511264999268e-08\n","step: 14200, loss: 0.0\n","step: 14300, loss: 0.020362455397844315\n","step: 14400, loss: 5.722039020383818e-08\n","step: 14500, loss: 2.0908219084958546e-06\n","step: 14600, loss: 1.430510998545742e-08\n","step: 14700, loss: 0.052951402962207794\n","step: 14800, loss: 2.38418573772492e-09\n","step: 14900, loss: 2.38418573772492e-09\n","step: 15000, loss: 2.6226029348208613e-08\n","step: 15100, loss: 0.0\n","step: 15200, loss: 0.0\n","step: 15300, loss: 7.15255632499634e-09\n","step: 15400, loss: 1.4042744851394673e-06\n","step: 15500, loss: 0.0\n","step: 15600, loss: 8.821468355790785e-08\n","step: 15700, loss: 4.29153317327291e-08\n","step: 15800, loss: 8.320635060954373e-07\n","step: 15900, loss: 0.12988053262233734\n","step: 16000, loss: 7.390962508679877e-08\n","step: 16100, loss: 1.0514063433220144e-06\n","step: 16200, loss: 1.1562968893485959e-06\n","step: 16300, loss: 1.9073014527748455e-06\n","step: 16400, loss: 1.478190370107768e-07\n","step: 16500, loss: 0.0\n","step: 16600, loss: 8.106223248205424e-08\n","step: 16700, loss: 8.344633073420482e-08\n","step: 16800, loss: 0.04771087318658829\n","step: 16900, loss: 0.0\n","step: 17000, loss: 2.1934411620350147e-07\n","step: 17100, loss: 4.519920821621781e-06\n","step: 17200, loss: 1.8524851839174516e-06\n","step: 17300, loss: 2.3841844054572903e-08\n","step: 17400, loss: 3.576277407546513e-08\n","step: 17500, loss: 2.38418573772492e-09\n","step: 17600, loss: 0.0\n","step: 17700, loss: 6.198826554282277e-07\n","step: 17800, loss: 5.698123004549416e-07\n","step: 17900, loss: 4.982894665772619e-07\n","step: 18000, loss: 2.145766764272139e-08\n","step: 18100, loss: 6.079609420339693e-07\n","step: 18200, loss: 0.0\n","step: 18300, loss: 2.176703446821193e-06\n","step: 18400, loss: 0.0\n","step: 18500, loss: 2.9887269192840904e-05\n","step: 18600, loss: 4.529947972287118e-08\n","step: 18700, loss: 9.53674117454284e-09\n","step: 18800, loss: 7.159634697018191e-05\n","step: 18900, loss: 0.23607875406742096\n","step: 19000, loss: 7.557758294751693e-07\n","step: 19100, loss: 2.145766941907823e-08\n","step: 19200, loss: 1.192092824453539e-08\n","step: 19300, loss: 4.76837103136063e-09\n","step: 19400, loss: 0.0\n","step: 19500, loss: 0.0\n","step: 19600, loss: 0.0\n","step: 19700, loss: 1.2302853974688333e-05\n","step: 19800, loss: 0.0\n","step: 19900, loss: 6.604136615351308e-07\n","step: 20000, loss: 3.8146950487316644e-08\n","step: 20100, loss: 2.2411288114199124e-07\n","step: 20200, loss: 0.0\n","step: 20300, loss: 0.0\n","step: 20400, loss: 0.0\n","step: 20500, loss: 0.0\n","step: 20600, loss: 5.3096333431312814e-05\n","step: 20700, loss: 0.0\n","step: 20800, loss: 0.4678615629673004\n","step: 20900, loss: 0.0001844034850364551\n","step: 21000, loss: 0.0\n","step: 21100, loss: 4.76837103136063e-09\n","step: 21200, loss: 0.21933609247207642\n","step: 21300, loss: 0.002271895995363593\n","step: 21400, loss: 1.0037295396614354e-05\n","step: 21500, loss: 1.0967230679170825e-07\n","step: 21600, loss: 0.0\n","step: 21700, loss: 0.0\n","step: 21800, loss: 5.245201961656676e-08\n","step: 21900, loss: 0.0\n","step: 22000, loss: 3.337857279461787e-08\n","step: 22100, loss: 0.0\n","step: 22200, loss: 0.0\n","step: 22300, loss: 0.0\n","step: 22400, loss: 5.602757937595015e-07\n","step: 22500, loss: 0.0\n","step: 22600, loss: 1.0244531267744605e-07\n","step: 22700, loss: 0.0\n","step: 22800, loss: 0.0\n","step: 22900, loss: 0.0\n","step: 23000, loss: 0.0\n","step: 23100, loss: 0.0\n","step: 23200, loss: 1.668929350273629e-08\n","step: 23300, loss: 0.12770746648311615\n","step: 23400, loss: 0.0\n","step: 23500, loss: 0.0\n","step: 23600, loss: 0.0\n","step: 23700, loss: 0.0\n","step: 23800, loss: 0.0002650289097800851\n","step: 23900, loss: 2.38418573772492e-09\n","step: 24000, loss: 0.045734111219644547\n","step: 24100, loss: 0.0\n","step: 24200, loss: 0.0001213390933116898\n","step: 24300, loss: 2.38418573772492e-09\n","step: 24400, loss: 0.0\n","step: 24500, loss: 2.8610209312773804e-08\n","step: 24600, loss: 0.0\n","step: 24700, loss: 0.0\n","step: 24800, loss: 0.0\n","step: 24900, loss: 0.0\n","step: 25000, loss: 0.0\n","step: 25100, loss: 0.0\n","step: 25200, loss: 0.0\n","step: 25300, loss: 0.0\n","step: 25400, loss: 0.0\n","step: 25500, loss: 0.0\n","step: 25600, loss: 0.06701381504535675\n","step: 25700, loss: 0.0\n","step: 25800, loss: 0.0\n","step: 25900, loss: 0.0\n","step: 26000, loss: 0.0637749582529068\n","step: 26100, loss: 0.0\n","step: 26200, loss: 0.0\n","step: 26300, loss: 0.0\n","step: 26400, loss: 7.15255676908555e-09\n","step: 26500, loss: 0.0\n","step: 26600, loss: 0.0\n","step: 26700, loss: 1.668929883180681e-08\n","step: 26800, loss: 0.0\n","step: 26900, loss: 2.622603290092229e-08\n","step: 27000, loss: 0.0\n","step: 27100, loss: 0.0\n","step: 27200, loss: 0.00016415331629104912\n","step: 27300, loss: 0.0\n","step: 27400, loss: 0.0\n","step: 27500, loss: 4.291529975830599e-08\n","step: 27600, loss: 1.430511264999268e-08\n","step: 27700, loss: 0.0\n","step: 27800, loss: 0.0\n","step: 27900, loss: 2.38418573772492e-09\n","step: 28000, loss: 1.6450817952318175e-07\n","step: 28100, loss: 0.059644341468811035\n","step: 28200, loss: 7.15255632499634e-09\n","step: 28300, loss: 0.0\n","step: 28400, loss: 4.0531130451881836e-08\n","step: 28500, loss: 0.0\n","step: 28600, loss: 0.0\n","step: 28700, loss: 8.583050714605633e-08\n","step: 28800, loss: 0.0\n","step: 28900, loss: 0.0\n","step: 29000, loss: 7.15255676908555e-09\n","step: 29100, loss: 0.0\n","step: 29200, loss: 0.0\n","step: 29300, loss: 9.53674117454284e-09\n","step: 29400, loss: 6.437292654482007e-08\n","step: 29500, loss: 0.0\n","step: 29600, loss: 3.0994389277338996e-08\n","step: 29700, loss: 1.192092646817855e-08\n","step: 29800, loss: 0.007377577014267445\n","step: 29900, loss: 0.0\n","step: 30000, loss: 3.8146946934602965e-08\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WVNYOITYozux","executionInfo":{"status":"ok","timestamp":1619533581627,"user_tz":-420,"elapsed":1007,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}}},"source":["def restore_parameters(name, epoch):\n","  filename = name.replace(':', '-colon-') + '-epoch-{}.txt'.format(epoch)\n","  with open(path + '/saved_paras/' + filename) as f:\n","    lines = f.read().splitlines()\n","  if len(lines) == 1:\n","    value = [float(number) for number in lines[0].split(',')]\n","  else:\n","    value = [[float(number) for number in lines[row].split(',')] for row in range(len(lines))]\n","  return value"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"2l5NsQmP3SUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619538298356,"user_tz":-420,"elapsed":2178,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}},"outputId":"72298e3d-65fe-48d0-c30e-a3820b81220a"},"source":["with tf.Session() as sess:\n","  trainable_variables = tf.trainable_variables()\n","  for variable in trainable_variables:\n","    saved_value = restore_parameters(variable.name, epoch = 132)\n","    assign_op = variable.assign(saved_value)\n","    sess.run(assign_op)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Tensor(\"Assign_40:0\", shape=(13973, 50), dtype=float32_ref)\n","Tensor(\"Assign_41:0\", shape=(50,), dtype=float32_ref)\n","Tensor(\"Assign_42:0\", shape=(50, 20), dtype=float32_ref)\n","Tensor(\"Assign_43:0\", shape=(20,), dtype=float32_ref)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTaJY8MOv21i","executionInfo":{"status":"ok","timestamp":1619536084502,"user_tz":-420,"elapsed":12692,"user":{"displayName":"Hữu Huy Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWvvArxofU_zXQPpF7b_62pIcjUilPxsRyO2c2Ow=s64","userId":"07784827418558933850"}},"outputId":"36126b22-2c14-4983-e780-e335b400c41d"},"source":["test_data_reader = DataReader(\n","  path = path + '/20news_test_tfidf.txt',\n","  batch_size = 50,\n","  vocab_size = vocab_size\n",")\n","\n","with tf.Session() as sess:\n","  epoch = 10\n","\n","  trainable_variables = tf.trainable_variables()\n","  for variable in trainable_variables:\n","    saved_value = restore_parameters(variable.name, epoch = 132)\n","    assign_op = variable.assign(saved_value)\n","    sess.run(assign_op)\n","\n","  num_true_preds = 0\n","  while True:\n","    test_data, test_labels = test_data_reader.next_batch()\n","    test_plabels_eval = sess.run(\n","        predicted_labels,\n","        feed_dict = {\n","            mlp._X: test_data,\n","            mlp._real_y: test_labels\n","        }\n","    )\n","    matches = np.equal(test_plabels_eval, test_labels)\n","    num_true_preds += np.sum(matches.astype('float'))\n","\n","    if test_data_reader._batch_id == 0:\n","      break\n","  \n","  print('epoch: ', epoch)\n","  print('accuracy on test data: ', num_true_preds / len(test_data_reader._data))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["epoch:  10\n","accuracy on test data:  0.7683218268720128\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CAKxFPEO3yyp"},"source":[],"execution_count":null,"outputs":[]}]}